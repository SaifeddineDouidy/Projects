{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2515364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When working with beautiulsoup, we have to specify the parser method\n",
    "# It is said that the best methode is lxml\n",
    "from bs4 import BeautifulSoup\n",
    "# How to access the content inside the html file\n",
    "# We have to work with file objects\n",
    "\n",
    "with open(#filename,r(w or a)) as html_file:\n",
    "    content = html_file.read()\n",
    "    # We use BeautifulSoup to work with the tags inside the html file\n",
    "    # to make it easier to scrape by making these tags as python objects\n",
    "    soup = BeautifulSoup(content, 'lxml')\n",
    "    #this next line of code makes it soo the information of the html to be \"prettier\"as in easier to read\n",
    "    print(soup.prettify())\n",
    "    # This next line of code will help us extract specific html tags\n",
    "    # But there is a twist this methode only returns one tag\n",
    "    tag = soup.find('a')\n",
    "    # This line does more it gives a list of the tag you chose to extract\n",
    "    tags = soup.find_all('a') \n",
    "    for ele in tags:\n",
    "        print(ele.text)# This returns only the text inside the tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ab749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(#filename,'r, w or a') as html_file:\n",
    "    content = html_file.read()\n",
    "    soup = BeautifulSoup(content,'lxml')\n",
    "    # The underscore is used to differentiate between the actual class defined in python prog language and \n",
    "    # between the class of a tag we want to extract data from\n",
    "    info = soup.find_all('div', class_='card')\n",
    "    for ele in info : \n",
    "        # This next line prints every h5 tag in the divs we specified the class of \n",
    "        print(ele.h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b74e840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# This library has alot of uses such as : requesting information from the server\n",
    "\n",
    "html_text = requests.get('https://www.svgrepo.com/vectors/education/').text\n",
    "soup = BeautifulSoup(html_text,'lxml')\n",
    "list_src = []\n",
    "list_img_tag = []\n",
    "list_full_url = []\n",
    "images_svg = soup.find_all('div', class_='style_Node__7ZTBP')\n",
    "\n",
    "for ele in images_svg:\n",
    "    list_src.append(ele.img.attrs['src'])\n",
    "\n",
    "for src in list_src:\n",
    "    url_base = \"https://www.svgrepo.com\"\n",
    "    full_url = url_base+src\n",
    "    list_full_url.append(full_url)\n",
    "\n",
    "for i in range(len(list_full_url)):\n",
    "    r = requests.get(list_full_url[i], stream=True) #Get request on full_url\n",
    "    if r.status_code == 200:                     #200 status code = OK\n",
    "        with open(f\"C:/HTML_CSS_JS/images/scraped{i}.svg\", 'wb') as f: \n",
    "            r.raw.decode_content = True\n",
    "            shutil.copyfileobj(r.raw, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae12441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_base = \"https://www.svgrepo.com\" #Original website\n",
    "url_ext = example.attrs['src'] #The extension you pulled earlier\n",
    "print(url_ext)\n",
    "full_url = url_base + url_ext #Combining first 2 variables to create       a complete URL\n",
    "print(full_url)\n",
    "r = requests.get(full_url, stream=True) #Get request on full_url\n",
    "if r.status_code == 200:                     #200 status code = OK\n",
    "    with open(\"C:/HTML_CSS_JS/images/scraped.svg\", 'wb') as f: \n",
    "        r.raw.decode_content = True\n",
    "        shutil.copyfileobj(r.raw, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad1f765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8372202d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90838844",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d894b6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bec121a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
